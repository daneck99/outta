{"cells":[{"cell_type":"markdown","metadata":{"id":"pOTQ_Pi9ckcR"},"source":["## 데이터셋 설명\n","- 본 데이터셋은 텍스트 정보와 직무에 대한 메타 정보로 구성되어 있습니다.\n","- 데이터셋에는 길이 제한이 없는 잡 포스팅과, 해당 포스팅이 진짜인지, 혹은 가짜인지의 여부가 포함되어 있습니다.\n","- 자연어(Natrual Language) 데이터, 그 중에서도 영어 데이터를 전처리하여 텍스트 데이터를 딥러닝에 적용하는 과정을 통해, 데이터 전처리와 특징 추출의 과정을 배워보시길 바랍니다.\n","\n","## 자연어 처리 (Natural Language Processing, NLP)\n","- 자연어 데이터를 머신러닝에 사용하기 위해서는 데이터를 머신러닝에 사용할 수 있도록 전처리하는 과정이 필요합니다.\n","- 일반적으로 머신러닝에 사용되는 데이터가 어떤 형태이고, 자연어가 이와 어떻게 다른지 생각해봅시다.\n","    - 데이터의 크기: 대부분의 머신러닝 모델들은 고정된 크기의 입력 데이터를 받습니다. 그러나, 자연어는 문장에 따라 길이가 상이합니다. 때문에 자연어를 머신러닝 모델에 투입하려면 데이터를 고정된 크기로 변환해줘야 합니다.\n","    - 데이터의 형태: 머신러닝 모델들은 실수 데이터를 입력 받습니다. 그러나, 자연어 데이터는 문자형(char, string)으로 되어있습니다.\n","- 이러한 문제들로 자연어 처리에서는 전처리 방식이 매우 중요합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BJyB2ewIckcW"},"outputs":[],"source":["# 라이브러리 임포트\n","import os\n","import random\n","from PIL import Image\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from tqdm import tqdm\n","\n","from sklearn.metrics import accuracy_score\n","\n","import torchvision\n","from torchvision.models import VGG16_Weights\n","from torchvision.transforms import v2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24035,"status":"ok","timestamp":1723855506225,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"8ohIqxavhJsj","outputId":"f46cd476-c49f-430c-fca0-bb92b8b82b8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FtnveeuckcY"},"outputs":[],"source":["# 하이퍼파라미터\n","args = {\n","    \"train_path\" : \"/content/gdrive/MyDrive/p1/train.csv\",      # train 데이터 경로\n","    \"test_path\" : \"/content/gdrive/MyDrive/p1/test.csv\",       # test 데이터 경로\n","    \"submit_path\" : \"/content/gdrive/MyDrive/p1/sample_submission.csv\",     # submit 파일 경로\n","    \"batch_size\" : 64,\n","    \"epochs\" : 1,\n","    \"lr\" : 2e-5,\n","    \"seed_val\" : 42         # 절대 수정하지 마세요.\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZdsOTZyckcY"},"outputs":[],"source":["# 랜덤시드 고정하기\n","seed = args[\"seed_val\"]\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available() :\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","# 디바이스 선택\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3713,"status":"ok","timestamp":1723855509935,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"9q9QY2rqckcZ","outputId":"09bac86f-ba2d-4063-9d5c-f90ebaf89574"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"]}],"source":["%pip install torchsummary ## model을 요약하기 위해 torchsummary 설치\n","from torchsummary import summary as summary_## 모델 정보를 확인하기 위해 torchsummary 함수 import\n","\n","## 모델의 형태를 출력하기 위한 함수\n","def summary_model(model, input_shape=(3,32,32)):\n","    model = model.to(device)\n","    summary_(model, input_shape) ## (model, (input shape))"]},{"cell_type":"markdown","metadata":{"id":"D33OtteUckcZ"},"source":["# **1. 데이터셋**"]},{"cell_type":"markdown","metadata":{"id":"nA1YjAzXckca"},"source":["## **(1) 데이터 불러오기 및 전처리**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb9bkPryckca"},"outputs":[],"source":["# 훈련 및 테스트 데이터 로드\n","train = pd.read_csv(args['train_path'])\n","test = pd.read_csv(args['test_path'])\n","\n","# (1-1) 훈련 데이터에서 특징(x_train)과 라벨(y_train) 분리\n","x_train = train.iloc[:,1:]# # 첫 번째 열을 제외한 모든 열 (특징)\n","y_train = train['label']# 'label' 열 (라벨)\n","x_test = test # 테스트 데이터\n","\n","# (1-2) numpy 배열로 변환 후, torch Tensor로 변환\n","x_train = torch.from_numpy(x_train.values).float()\n","y_train = torch.from_numpy(y_train.values).long()\n","x_test = torch.from_numpy(x_test.values).float()\n","\n","# (1-3) 데이터를 (N, H, W, C) 형태로 재구성 (reshape 함수 이용)\n","x_train = x_train.reshape(-1,28,28,1)\n","x_test = x_test.reshape(-1,28,28,1)\n","\n","# (1-4) 데이터를 (N, C, H, W) 형태로 변환 (permute 함수 이용)\n","x_train = x_train.permute(0,3,1,2)\n","x_test = x_test.permute(0,3,1,2)\n","\n","# (1-5) 데이터를 (N, 3, 28, 28) 형태로 변환 (expand 함수 이용)\n","x_train = x_train.expand(-1,3,-1,-1)\n","x_test = x_test.expand(-1,3,-1,-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1723855521628,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"ZC8qw1d5ckca","outputId":"b5ec405e-5adb-44dd-e511-ada1442e9819"},"outputs":[{"data":{"text/plain":["torch.Size([27455, 3, 28, 28])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1723855521628,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"5UEJN8puckcb","outputId":"2453422d-49ef-4f95-d7ce-f20b645106c6"},"outputs":[{"data":{"text/plain":["torch.Size([7172, 3, 28, 28])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x_test.shape"]},{"cell_type":"markdown","metadata":{"id":"X-EwlYgWckcb"},"source":["## **(2) 데이터셋과 데이터로더**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vy0_9ODrckcc"},"outputs":[],"source":["# 훈련 및 테스트 데이터셋 로드\n","train_dataset = TensorDataset(x_train, y_train)\n","test_dataset = TensorDataset(x_test)\n","\n","# 데이터로더 정의\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=args[\"batch_size\"], shuffle=True)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"E6eFsvANckcc"},"source":["# **2. 모델**\n","사전학습된 VGG16을 사용하여 프로젝트를 수행하세요."]},{"cell_type":"markdown","metadata":{"id":"ynVCx9Emckcc"},"source":["## **(1) VGG16 특징 추출기를 불러오기**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9887,"status":"ok","timestamp":1723855563143,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"dsEGfxjVckcc","outputId":"7f510d9f-2173-4f10-9c36-e67bf70fb81e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:05<00:00, 94.2MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","              ReLU-2           [-1, 64, 32, 32]               0\n","            Conv2d-3           [-1, 64, 32, 32]          36,928\n","              ReLU-4           [-1, 64, 32, 32]               0\n","         MaxPool2d-5           [-1, 64, 16, 16]               0\n","            Conv2d-6          [-1, 128, 16, 16]          73,856\n","              ReLU-7          [-1, 128, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]         147,584\n","              ReLU-9          [-1, 128, 16, 16]               0\n","        MaxPool2d-10            [-1, 128, 8, 8]               0\n","           Conv2d-11            [-1, 256, 8, 8]         295,168\n","             ReLU-12            [-1, 256, 8, 8]               0\n","           Conv2d-13            [-1, 256, 8, 8]         590,080\n","             ReLU-14            [-1, 256, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         590,080\n","             ReLU-16            [-1, 256, 8, 8]               0\n","        MaxPool2d-17            [-1, 256, 4, 4]               0\n","           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n","             ReLU-19            [-1, 512, 4, 4]               0\n","           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n","             ReLU-21            [-1, 512, 4, 4]               0\n","           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n","             ReLU-23            [-1, 512, 4, 4]               0\n","        MaxPool2d-24            [-1, 512, 2, 2]               0\n","           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n","             ReLU-26            [-1, 512, 2, 2]               0\n","           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n","             ReLU-28            [-1, 512, 2, 2]               0\n","           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n","             ReLU-30            [-1, 512, 2, 2]               0\n","        MaxPool2d-31            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                 [-1, 1000]       4,097,000\n","================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 4.84\n","Params size (MB): 527.79\n","Estimated Total Size (MB): 532.65\n","----------------------------------------------------------------\n"]}],"source":["# (3-1) VGG16 모델 로드 및 특징 추출 부분 사용\n","# 가중치는 'VGG16_Weights.IMAGENET1K_V1' 사용하세요.\n","model = torchvision.models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n","\n","# (3-2) 모델에 글로벌 평균 풀링 계층 추가\n","model.global_avg_pool2d = nn.AdaptiveAvgPool2d(output_size=(1,1))\n","\n","# 모델 요약 정보 출력\n","summary_model(model)"]},{"cell_type":"markdown","metadata":{"id":"DLFto6udckcd"},"source":["## **(2) VGG16 특징 추출기를 동결시키기**\n","1. 계산 비용 절감:\n","    - 모델의 일부 파라미터를 동결하면 그 부분은 학습되지 않기 때문에 계산량이 줄어듭니다.\n","\n","    - 이는 학습 속도를 빠르게 하고, GPU 메모리 사용량을 줄이는 데 도움이 됩니다.\n","\n","2. 오버피팅 방지:\n","    - 작은 데이터셋을 사용할 때 모델이 쉽게 오버피팅될 수 있습니다.\n","    \n","    - 이미 학습된 파라미터를 동결하면 모델이 새로운 데이터에 맞춰 과도하게 학습되는 것을 방지할 수 있습니다.\n","\n","\n","3. 전이 학습(Transfer Learning):\n","    - 사전 학습된 모델(예: ImageNet 데이터셋으로 학습된 모델)의 초반 레이어는 일반적인 특징(예: 에지, 텍스처 등)을 잘 잡아냅니다.\n","\n","    - 이러한 특징을 이용하면 새로운 데이터셋에서도 좋은 성능을 낼 수 있습니다.\n","\n","    - 모델의 후반 레이어만 재학습하여 새로운 데이터셋에 맞출 수 있습니다.\n","\n","4. 더 빠른 수렴:\n","    - 동결된 파라미터는 변화하지 않으므로 모델이 더 빠르게 수렴할 수 있습니다.\n","    \n","    - 이는 전체 학습 시간을 단축시키는 데 도움이 됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1723855571045,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"X6NfbTWzckcd","outputId":"be16e501-bd11-4c93-e390-c7045f88a8b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","              ReLU-2           [-1, 64, 32, 32]               0\n","            Conv2d-3           [-1, 64, 32, 32]          36,928\n","              ReLU-4           [-1, 64, 32, 32]               0\n","         MaxPool2d-5           [-1, 64, 16, 16]               0\n","            Conv2d-6          [-1, 128, 16, 16]          73,856\n","              ReLU-7          [-1, 128, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]         147,584\n","              ReLU-9          [-1, 128, 16, 16]               0\n","        MaxPool2d-10            [-1, 128, 8, 8]               0\n","           Conv2d-11            [-1, 256, 8, 8]         295,168\n","             ReLU-12            [-1, 256, 8, 8]               0\n","           Conv2d-13            [-1, 256, 8, 8]         590,080\n","             ReLU-14            [-1, 256, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         590,080\n","             ReLU-16            [-1, 256, 8, 8]               0\n","        MaxPool2d-17            [-1, 256, 4, 4]               0\n","           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n","             ReLU-19            [-1, 512, 4, 4]               0\n","           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n","             ReLU-21            [-1, 512, 4, 4]               0\n","           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n","             ReLU-23            [-1, 512, 4, 4]               0\n","        MaxPool2d-24            [-1, 512, 2, 2]               0\n","           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n","             ReLU-26            [-1, 512, 2, 2]               0\n","           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n","             ReLU-28            [-1, 512, 2, 2]               0\n","           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n","             ReLU-30            [-1, 512, 2, 2]               0\n","        MaxPool2d-31            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                 [-1, 1000]       4,097,000\n","================================================================\n","Total params: 138,357,544\n","Trainable params: 130,722,280\n","Non-trainable params: 7,635,264\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 4.84\n","Params size (MB): 527.79\n","Estimated Total Size (MB): 532.65\n","----------------------------------------------------------------\n"]}],"source":["# 모델의 앞부분 파라미터 고정 (동결)\n","for para in model.features[:-8].parameters():\n","    para.requires_grad = False\n","\n","# 파라미터 동결 후 모델 요약 정보 출력\n","summary_model(model)"]},{"cell_type":"markdown","metadata":{"id":"Crc483Mjckcd"},"source":["## **(3) VGG16 분류기를 만들기**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":11,"status":"error","timestamp":1723872836890,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"YJkaXKu1ckcd","outputId":"7d908dd5-0623-4d51-83d5-24dc6e6b5a7b"},"outputs":[{"ename":"NameError","evalue":"name 'nn' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-cdc0273b502d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (4-1) 새로운 분류기 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m classifier = nn.Sequential(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 25개의 클래스로 분류\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# VGG16의 마지막 conv layer 출력이 512 채널이고, AdaptiveAvgPool2d로 1x1로 줄였으므로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}],"source":["# (4-1) 새로운 분류기 정의\n","classifier = nn.Sequential(  ## 이거 바꾸는 듯\n","    # 25개의 클래스로 분류\n","    nn.Linear(512 * 1 * 1, 4096),  # VGG16의 마지막 conv layer 출력이 512 채널이고, AdaptiveAvgPool2d로 1x1로 줄였으므로\n","    nn.BatchNorm1d(4096)\n","    nn.ReLU(),\n","    nn.Dropout(p=0.5),\n","    nn.Linear(4096, 1024),\n","    nn.ReLU(),\n","    nn.Dropout(p=0.5),\n","    nn.Linear(1024, 25)  # 최종 출력을 25개 클래스로 설정\n",")\n","\n","# (4-2) 모델에 새로운 분류기 추가\n","model.classifier = classifier\n","model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","# 모델을 장치로 이동\n","model = model.to(device)\n","\n","# 최종 모델 요약 정보 출력\n","summary_model(model)"]},{"cell_type":"markdown","metadata":{"id":"CcTUfJlqckce"},"source":["# **3. 학습**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":564,"status":"ok","timestamp":1723855828837,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"v7gjrZnqckce","outputId":"f0f73556-715f-42ea-9a84-6b726eb2ef4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["ImageClassification(\n","    crop_size=[224]\n","    resize_size=[32]\n","    mean=[0.485, 0.456, 0.406]\n","    std=[0.229, 0.224, 0.225]\n","    interpolation=InterpolationMode.BILINEAR\n",")\n"]}],"source":["# VGG16에서 사용한 transform을 이용\n","transform = VGG16_Weights.DEFAULT.transforms(antialias=False)\n","\n","# resize 크기는 32가 되도록 설정\n","transform.resize_size=[32]\n","\n","# transform 확인하기\n","print(transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"elapsed":93086,"status":"error","timestamp":1723855922446,"user":{"displayName":"이강룡","userId":"03002945986942853653"},"user_tz":-540},"id":"uI3WdAdrckce","outputId":"46dc09b0-f838-467c-f413-535b8681f3f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1\n"]},{"name":"stderr","output_type":"stream","text":[" 56%|█████▋    | 242/429 [01:33<01:11,  2.60it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-c9de85d27018>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-c9de85d27018>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, model, device, args)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# loss 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# accaracy 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch.optim as optim\n","def train(train_dataloader, model, device, args):\n","    \"\"\"\n","    주어진 데이터로 모델을 학습시키는 함수입니다.\n","\n","    Args:\n","        train_dataloader (DataLoader): 학습 데이터를 제공하는 DataLoader 객체\n","        valid_dataloader (DataLoader): 검증 데이터를 제공하는 DataLoader 객체\n","        model (torch.nn.Module): 학습할 모델\n","        device (torch.device): 사용할 디바이스 (CPU 또는 GPU)\n","        args (dict): 학습 관련 인자들을 포함한 딕셔너리\n","\n","    Returns:\n","        None\n","    \"\"\"\n","\n","    # (5-1) Adam 옵티마이저와 교차 엔트로피 손실 함수 정의\n","    optimizer = optim.Adam(model.parameters(), lr=args[\"lr\"])\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    model.zero_grad()  # 모델의 그래디언트 초기화\n","\n","    for epoch in range(args[\"epochs\"]):\n","        model.train()       # 모델을 훈련 모드로 설정\n","\n","        total_loss = 0      # 전체 손실 초기화\n","        total_accuracy = 0  # 전체 정확도 초기화\n","\n","        print(f'Epoch {epoch + 1}/{args[\"epochs\"]}')\n","\n","        for image, label in tqdm(train_dataloader):\n","            image = transform(image).to(device)\n","            label = label.to(device)\n","\n","            # (5-2) 모델을 사용하여 예측 수행\n","            pred = model(image)\n","\n","            # (5-3) 손실 계산 및 누적\n","            loss = loss_fn(pred, label)\n","\n","            # (5-4) 역전파를 통해 기울기 계산\n","            loss.backward()\n","\n","            # (5-5) 파라미터 업데이트\n","            optimizer.step()\n","\n","            # (5-6) 모델의 그래디언트 초기화\n","            optimizer.zero_grad()\n","\n","            # loss 계산\n","            total_loss += loss.item()\n","\n","            # accaracy 계산\n","            label = label.cpu()\n","            pred = pred.argmax(dim = 1).cpu()\n","            accuracy = accuracy_score(label, pred)\n","            total_accuracy += accuracy\n","\n","        # 평균 손실과 정확도 계산\n","        avg_loss = total_loss / len(train_dataloader)\n","        avg_accuracy = total_accuracy / len(train_dataloader)\n","\n","        # 모델 체크포인트 저장\n","        os.makedirs(\"results\", exist_ok=True)\n","        torch.save({\n","            'epoch': epoch,\n","            'model': model,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': loss.item,\n","            }, f'./results/model_state_dict_epoch_{epoch+1}.pth')\n","\n","        # 현재 에포크의 손실과 정확도 출력\n","        print(f'CheckPoint : model_state_dict_epoch_{epoch+1}.pth')\n","        print(f'train_loss : {avg_loss}, train_acc : {avg_accuracy}\\n')\n","\n","\n","if __name__ == \"__main__\":\n","    train(train_dataloader, model, device, args)"]},{"cell_type":"markdown","metadata":{"id":"kTAfgSHLckce"},"source":["# **4. 평가**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmjumWvtckce"},"outputs":[],"source":["def test(test_dataloader, model, device):\n","    \"\"\"\n","    모델의 테스트를 수행하는 함수입니다.\n","\n","    Args:\n","        test_dataloader (DataLoader): 테스트 데이터를 제공하는 DataLoader 객체\n","        model (torch.nn.Module): 평가할 모델\n","        device (torch.device): 사용할 디바이스 (CPU 또는 GPU)\n","\n","    Returns:\n","        preds (list): 각 입력 예시에 대한 모델의 예측 결과 리스트\n","    \"\"\"\n","    model.eval()    # 모델을 평가 모드로 설정\n","    preds = []      # 예측 결과를 저장할 리스트\n","\n","    # 각 배치에 대해 예측 수행\n","    for image in tqdm(test_dataloader):\n","        image = transform(image[0]).to(device)\n","\n","        # 기울기 계산을 비활성화하여 예측 수행\n","        with torch.no_grad():\n","            # (6-1) 모델에 입력을 전달하여 예측 수행\n","            pred = model(image)\n","\n","            # (6-2) argmax를 이용하여 예측 결과에서 가장 높은 값의 인덱스를 선택\n","            pred = pred.argmax(dim = 1)\n","\n","            # (6-3) 예측 결과를 CPU로 이동\n","            pred = pred.cpu()\n","\n","            # (6-4) 예측을 numpy 배열로 변환\n","            pred = pred.numpy()\n","\n","            # (6-5) 예측 결과를 리스트에 추가\n","            preds.append(pred)\n","\n","    return preds\n","\n","\n","if __name__ == \"__main__\":\n","    # 예측값을 얻기 위해 test 함수 호출\n","    preds = test(test_dataloader, model, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hrtvfGLckcf"},"outputs":[],"source":["submit = pd.read_csv(args[\"submit_path\"])\n","submit[\"label\"] = preds\n","submit.to_csv(\"submission_p1.csv\", index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9aDiwC1Nckcf"},"outputs":[],"source":["submit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gy5z_OAackcf"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}
