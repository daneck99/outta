{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 설명\n",
    "- 본 데이터셋은 텍스트 정보와 직무에 대한 메타 정보로 구성되어 있습니다.\n",
    "- 데이터셋에는 길이 제한이 없는 잡 포스팅과, 해당 포스팅이 진짜인지, 혹은 가짜인지의 여부가 포함되어 있습니다.\n",
    "- 자연어(Natrual Language) 데이터, 그 중에서도 영어 데이터를 전처리하여 텍스트 데이터를 딥러닝에 적용하는 과정을 통해, 데이터 전처리와 특징 추출의 과정을 배워보시길 바랍니다.\n",
    "\n",
    "## 자연어 처리 (Natural Language Processing, NLP)\n",
    "- 자연어 데이터를 머신러닝에 사용하기 위해서는 데이터를 머신러닝에 사용할 수 있도록 전처리하는 과정이 필요합니다.\n",
    "- 일반적으로 머신러닝에 사용되는 데이터가 어떤 형태이고, 자연어가 이와 어떻게 다른지 생각해봅시다.\n",
    "    - 데이터의 크기: 대부분의 머신러닝 모델들은 고정된 크기의 입력 데이터를 받습니다. 그러나, 자연어는 문장에 따라 길이가 상이합니다. 때문에 자연어를 머신러닝 모델에 투입하려면 데이터를 고정된 크기로 변환해줘야 합니다.\n",
    "    - 데이터의 형태: 머신러닝 모델들은 실수 데이터를 입력 받습니다. 그러나, 자연어 데이터는 문자형(char, string)으로 되어있습니다.\n",
    "- 이러한 문제들로 자연어 처리에서는 전처리 방식이 매우 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models import VGG16_Weights\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "args = {\n",
    "    \"train_path\" : \"\",      # train 데이터 경로\n",
    "    \"test_path\" : \"\",       # test 데이터 경로\n",
    "    \"submit_path\" : \"\",     # submit 파일 경로\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 1,\n",
    "    \"lr\" : 2e-5,\n",
    "    \"seed_val\" : 42         # 절대 수정하지 마세요.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤시드 고정하기\n",
    "seed = args[\"seed_val\"]\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available() : \n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 디바이스 선택\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchsummary ## model을 요약하기 위해 torchsummary 설치\n",
    "from torchsummary import summary as summary_## 모델 정보를 확인하기 위해 torchsummary 함수 import\n",
    "\n",
    "## 모델의 형태를 출력하기 위한 함수 \n",
    "def summary_model(model, input_shape=(3,32,32)):\n",
    "    model = model.to(device)\n",
    "    summary_(model, input_shape) ## (model, (input shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. 데이터셋**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **(1) 데이터 불러오기 및 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 테스트 데이터 로드\n",
    "train = pd.read_csv(args['train_path'])\n",
    "test = pd.read_csv(args['test_path'])\n",
    "\n",
    "# (1-1) 훈련 데이터에서 특징(x_train)과 라벨(y_train) 분리\n",
    "x_train =   # 첫 번째 열을 제외한 모든 열 (특징)\n",
    "y_train =   # 'label' 열 (라벨)\n",
    "x_test =    # 테스트 데이터\n",
    "\n",
    "# (1-2) numpy 배열로 변환 후, torch Tensor로 변환\n",
    "x_train = \n",
    "y_train = \n",
    "x_test = \n",
    "\n",
    "# (1-3) 데이터를 (N, H, W, C) 형태로 재구성 (reshape 함수 이용)\n",
    "x_train = \n",
    "x_test = \n",
    "\n",
    "# (1-4) 데이터를 (N, C, H, W) 형태로 변환 (permute 함수 이용)\n",
    "x_train = \n",
    "x_test = \n",
    "\n",
    "# (1-5) 데이터를 (N, 3, 28, 28) 형태로 변환 (expand 함수 이용)\n",
    "x_train = \n",
    "x_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **(2) 데이터셋과 데이터로더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 테스트 데이터셋 로드\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test)\n",
    "\n",
    "# 데이터로더 정의\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=args[\"batch_size\"], shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. 모델**\n",
    "사전학습된 VGG16을 사용하여 프로젝트를 수행하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **(1) VGG16 특징 추출기를 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3-1) VGG16 모델 로드 및 특징 추출 부분 사용\n",
    "# 가중치는 'VGG16_Weights.IMAGENET1K_V1' 사용하세요.\n",
    "model = \n",
    "\n",
    "# (3-2) 모델에 글로벌 평균 풀링 계층 추가\n",
    "model.global_avg_pool2d = \n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "summary_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **(2) VGG16 특징 추출기를 동결시키기**\n",
    "1. 계산 비용 절감:\n",
    "    - 모델의 일부 파라미터를 동결하면 그 부분은 학습되지 않기 때문에 계산량이 줄어듭니다. \n",
    "\n",
    "    - 이는 학습 속도를 빠르게 하고, GPU 메모리 사용량을 줄이는 데 도움이 됩니다.\n",
    "\n",
    "2. 오버피팅 방지:\n",
    "    - 작은 데이터셋을 사용할 때 모델이 쉽게 오버피팅될 수 있습니다. \n",
    "    \n",
    "    - 이미 학습된 파라미터를 동결하면 모델이 새로운 데이터에 맞춰 과도하게 학습되는 것을 방지할 수 있습니다.\n",
    "\n",
    "\n",
    "3. 전이 학습(Transfer Learning):\n",
    "    - 사전 학습된 모델(예: ImageNet 데이터셋으로 학습된 모델)의 초반 레이어는 일반적인 특징(예: 에지, 텍스처 등)을 잘 잡아냅니다. \n",
    "\n",
    "    - 이러한 특징을 이용하면 새로운 데이터셋에서도 좋은 성능을 낼 수 있습니다. \n",
    "\n",
    "    - 모델의 후반 레이어만 재학습하여 새로운 데이터셋에 맞출 수 있습니다.\n",
    "\n",
    "4. 더 빠른 수렴:\n",
    "    - 동결된 파라미터는 변화하지 않으므로 모델이 더 빠르게 수렴할 수 있습니다. \n",
    "    \n",
    "    - 이는 전체 학습 시간을 단축시키는 데 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 앞부분 파라미터 고정 (동결)\n",
    "for para in model[:-8].parameters(): \n",
    "    para.requires_grad = False\n",
    "\n",
    "# 파라미터 동결 후 모델 요약 정보 출력\n",
    "summary_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **(3) VGG16 분류기를 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4-1) 새로운 분류기 정의\n",
    "classifier = nn.Sequential(\n",
    "    # 25개의 클래스로 분류\n",
    "    \n",
    ")\n",
    "\n",
    "# (4-2) 모델에 새로운 분류기 추가\n",
    "model.classifier = \n",
    "\n",
    "# 모델을 장치로 이동\n",
    "model = model.to(device)\n",
    "\n",
    "# 최종 모델 요약 정보 출력\n",
    "summary_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16에서 사용한 transform을 이용\n",
    "transform = VGG16_Weights.DEFAULT.transforms(antialias=False)\n",
    "\n",
    "# resize 크기는 32가 되도록 설정\n",
    "transform.resize_size=[32]\n",
    "\n",
    "# transform 확인하기\n",
    "print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, device, args):\n",
    "    \"\"\"\n",
    "    주어진 데이터로 모델을 학습시키는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        train_dataloader (DataLoader): 학습 데이터를 제공하는 DataLoader 객체\n",
    "        valid_dataloader (DataLoader): 검증 데이터를 제공하는 DataLoader 객체\n",
    "        model (torch.nn.Module): 학습할 모델\n",
    "        device (torch.device): 사용할 디바이스 (CPU 또는 GPU)\n",
    "        args (dict): 학습 관련 인자들을 포함한 딕셔너리\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # (5-1) Adam 옵티마이저와 교차 엔트로피 손실 함수 정의\n",
    "    optimizer = \n",
    "    loss_fn = \n",
    "    \n",
    "    model.zero_grad()  # 모델의 그래디언트 초기화\n",
    "    \n",
    "    for epoch in range(args[\"epochs\"]):\n",
    "        model.train()       # 모델을 훈련 모드로 설정\n",
    "        \n",
    "        total_loss = 0      # 전체 손실 초기화\n",
    "        total_accuracy = 0  # 전체 정확도 초기화\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{args[\"epochs\"]}')\n",
    "        \n",
    "        for image, label in tqdm(train_dataloader):\n",
    "            image = transform(image).to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # (5-2) 모델을 사용하여 예측 수행\n",
    "            pred = \n",
    "            \n",
    "            # (5-3) 손실 계산 및 누적\n",
    "            loss = \n",
    "            \n",
    "            # (5-4) 역전파를 통해 기울기 계산\n",
    "            \n",
    "            \n",
    "            # (5-5) 파라미터 업데이트\n",
    "            \n",
    "            \n",
    "            # (5-6) 모델의 그래디언트 초기화\n",
    "            \n",
    "            \n",
    "            # loss 계산\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # accaracy 계산\n",
    "            label = label.cpu()\n",
    "            pred = pred.argmax(dim = 1).cpu()\n",
    "            accuracy = accuracy_score(label, pred)\n",
    "            total_accuracy += accuracy\n",
    "        \n",
    "        # 평균 손실과 정확도 계산\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        avg_accuracy = total_accuracy / len(train_dataloader)\n",
    "        \n",
    "        # 모델 체크포인트 저장\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item,\n",
    "            }, f'./results/model_state_dict_epoch_{epoch+1}.pth')\n",
    "        \n",
    "        # 현재 에포크의 손실과 정확도 출력\n",
    "        print(f'CheckPoint : model_state_dict_epoch_{epoch+1}.pth')\n",
    "        print(f'train_loss : {avg_loss}, train_acc : {avg_accuracy}\\n')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train(train_dataloader, model, device, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_dataloader, model, device):\n",
    "    \"\"\"\n",
    "    모델의 테스트를 수행하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        test_dataloader (DataLoader): 테스트 데이터를 제공하는 DataLoader 객체\n",
    "        model (torch.nn.Module): 평가할 모델\n",
    "        device (torch.device): 사용할 디바이스 (CPU 또는 GPU)\n",
    "\n",
    "    Returns:\n",
    "        preds (list): 각 입력 예시에 대한 모델의 예측 결과 리스트\n",
    "    \"\"\"\n",
    "    model.eval()    # 모델을 평가 모드로 설정\n",
    "    preds = []      # 예측 결과를 저장할 리스트\n",
    "    \n",
    "    # 각 배치에 대해 예측 수행\n",
    "    for image in tqdm(test_dataloader):\n",
    "        image = transform(image[0]).to(device)\n",
    "        \n",
    "        # 기울기 계산을 비활성화하여 예측 수행\n",
    "        with torch.no_grad():\n",
    "            # (6-1) 모델에 입력을 전달하여 예측 수행\n",
    "            \n",
    "            \n",
    "            # (6-2) argmax를 이용하여 예측 결과에서 가장 높은 값의 인덱스를 선택\n",
    "            \n",
    "\n",
    "            # (6-3) 예측 결과를 CPU로 이동\n",
    "            \n",
    "\n",
    "            # (6-4) 예측을 numpy 배열로 변환\n",
    "            \n",
    "\n",
    "            # (6-5) 예측 결과를 리스트에 추가\n",
    "            \n",
    "    \n",
    "    return preds\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 예측값을 얻기 위해 test 함수 호출\n",
    "    preds = test(test_dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(args[\"submit_path\"])\n",
    "submit[\"label\"] = preds\n",
    "submit.to_csv(\"submission_p1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
